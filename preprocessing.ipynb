{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "preprocessing.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/dataset.csv')\n",
        "df1 = df.drop(columns=\"html\")\n",
        "df1.rename(columns={\"source\": \"url\"}, inplace=True)\n",
        "df1.to_csv('preprocess_dataset.csv')"
      ],
      "metadata": {
        "id": "jPar64qXYn4l"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/tweets-extracted-from-bajaj-finserv-twitter.csv')\n",
        "df1 = df.drop(columns=\"Datetime\")\n",
        "df2 = df1.drop(columns=\"Tweet Id\")\n",
        "df3 = df2.drop(columns=\"Username\")\n",
        "df3.to_csv('preprocess_twitter_dataset.csv')\n"
      ],
      "metadata": {
        "id": "KNUIPLRqonPu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/paras-and-lines-website-scraped.csv')\n",
        "df2 = pd.read_csv('/content/preprocess_twitter_dataset.csv')\n",
        "df3 = df2.drop(columns=\"Unnamed: 0\")\n",
        "df3.rename(columns={\"Text\": \"lines\"}, inplace=True)\n",
        "df3.head()\n",
        "concate_data = pd.concat([df1,df3])\n",
        "concate_data.to_csv(\"concat_data.csv\")"
      ],
      "metadata": {
        "id": "p707L-2Ap17V"
      },
      "execution_count": 57,
      "outputs": []
    }
  ]
}